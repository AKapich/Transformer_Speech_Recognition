
# Architectures
Apart from the transformer architectures such as Audio Spectrogram Transformer (tailored for audio data), we also intend to explore other architectures like RNNs (LSTM / GRU), alternatively CNN architectures


# Project steps

### Week 1-2
1. Explore further details about audio data representation like spectrograms. Research techniques for audio data augmentation.

2. Learn more about aforementioned architectures and their application to audio data. Get familiar with papers such as 'Attention is all you need' and 'Audio Spectrogram Transformer'.

3. Explore the dataset: structure, classes, audio characteristics, and the challenges posed by "silence" and "unknown" classes. Analyse how to address computational efficiency issues (whether limiting amount of classes or using a subset of the dataset will make do).

4. Implement the architectures and auxiliary functions.

### Week 2-3
5. Test different parameter settings for chosen architectures (both training parameters such as optimizers, learning rate etc. and architecture parameters such as number of attention heads, number of encoder layers for transformers). Evaluate the performance of the models.

6. Write a report summarizing the project
